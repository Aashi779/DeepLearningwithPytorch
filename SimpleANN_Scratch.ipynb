{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+xnCzCFUtfWufbyDONuzb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aashi779/DeepLearningwithPytorch/blob/main/SimpleANN_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ffqHBm9HQU6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([\n",
        "    [1,0,1,0],\n",
        "    [1,0,1,1],\n",
        "    [0,1,0,1]\n",
        "])\n",
        "\n",
        "y = np.array([[1],[1],[0]])"
      ],
      "metadata": {
        "id": "R3y1n-sCQdn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvVH67r2Qik5",
        "outputId": "a9443d6d-0114-46e8-9e9e-5e57c76e6c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 1, 0],\n",
              "       [1, 0, 1, 1],\n",
              "       [0, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFkIgK85QkF0",
        "outputId": "4801ac6c-d239-42cd-a8b3-8a42b8c0b650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activation Functions**\n",
        "\n",
        "- Decide whether a neuron should be activated or not. Whether the information that the neuron is receiving is relevant for the given information or should it be ignored.\n",
        "- It is the non linear transformation that we do over the input signal. This transformed output is then send to the next layer of neurons as input.\n",
        "- Without activation function neural network will only be performing linear transformation on the input.\n",
        "- A linear equation is simple to solve but is limited in its capacity to solve complex problems. A neural network without an activation function is essentially just a linear regression model."
      ],
      "metadata": {
        "id": "WOa4hBgCQ8RB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation function\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))"
      ],
      "metadata": {
        "id": "-olR0bSQQley"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape # gives a tuple"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RrUkA7MQvRk",
        "outputId": "bfd36874-43f2-4330-ae1a-c0b9ea0da692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input layer neurons will be always equals to the number of columns\n",
        "inputNeurons = x.shape[1]\n",
        "# hidden neurons we can decide by hit and trial\n",
        "hiddenNeurons = 3\n",
        "# output neurons depends on number of classes we have in target column,for eg to classify 0 and 1\n",
        "outputNeurons = 1"
      ],
      "metadata": {
        "id": "aNVwE29lRj47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weightsHidden = np.random.uniform(size=(inputNeurons, hiddenNeurons)) # (4,3)\n",
        "biasHidden = np.random.uniform(size=(1, hiddenNeurons)) #(1,3)\n",
        "weightsOutput = np.random.uniform(size=(hiddenNeurons, outputNeurons)) #(3,1)\n",
        "biasOutput = np.random.uniform(size=(1, outputNeurons)) #(1,1)"
      ],
      "metadata": {
        "id": "BftZuMeMRoqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feedforward\n",
        "\n",
        "# Step 1 - apply dot product and add bias : f(x) = x.wh + biasHidden\n",
        "fx = np.dot(x, weightsHidden) + biasHidden\n",
        "\n",
        "# Step 2 - apply activation function\n",
        "hiddenLayer = sigmoid(fx)\n",
        "hiddenLayer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP14CZmDRtF7",
        "outputId": "8568769e-fcb1-4e6b-8acd-892bf399cbe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.70128954, 0.92769703, 0.87847941],\n",
              "       [0.84379137, 0.93391848, 0.94265152],\n",
              "       [0.77273892, 0.78806868, 0.84723194]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-3 - apply dot product and add bias : f(x) = hiddenLayer.wout + biasOut\n",
        "fx_ = np.dot(hiddenLayer, weightsOutput) + biasOutput\n",
        "fx_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjyWSdhpRwd5",
        "outputId": "2133a797-2e76-435f-dfb2-73506f7378fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.49062423],\n",
              "       [2.62208729],\n",
              "       [2.41045676]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bias"
      ],
      "metadata": {
        "id": "VvhEXdpeJrRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "biasHidden"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olPoVY17R26_",
        "outputId": "40f551f7-2fdd-4a62-fcdb-f1cc24f8db55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.24137394, 0.93698264, 0.79138208]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "biasOutput"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw8YO_TfR5DX",
        "outputId": "4c366c12-82b1-46d2-94b1-8ca9bb59ee3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.91456034]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputLayer = sigmoid(fx_) # applying activation on output layer"
      ],
      "metadata": {
        "id": "d1xYVsoMR6Yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputLayer #predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IPSdVXJ109s",
        "outputId": "5236d80a-b907-448d-848f-a0dc895ae695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.92348192],\n",
              "       [0.93226962],\n",
              "       [0.91762122]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def derivativeSigmoid(x):\n",
        "  return x * (1 - x)"
      ],
      "metadata": {
        "id": "YLt3OT9sR-KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Backpropagation -\n",
        "# calculate loss(y - y^) and optimization of weights and bias\n",
        "# calc slope of activation function(derivative)\n",
        "# delta - loss*slope"
      ],
      "metadata": {
        "id": "0AxjyqmUSB2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Error on output layer\n",
        "errorOutput = outputLayer - y\n",
        "# Slope on output layer - derivative of activation function applied on this layer\n",
        "slopeOutput = derivativeSigmoid(outputLayer)\n",
        "# Delta = error x slope\n",
        "deltaOutput = errorOutput * slopeOutput"
      ],
      "metadata": {
        "id": "VAHClqaD7oS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for hidden layer\n",
        "errorHidden = np.dot(deltaOutput, weightsOutput.T)\n",
        "slopeHidden = derivativeSigmoid(hiddenLayer)\n",
        "deltaHidden = errorHidden * slopeHidden"
      ],
      "metadata": {
        "id": "aJ4ZNBNv7jjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errorOutput # this has to be minimized"
      ],
      "metadata": {
        "id": "ig7vuCHvSGsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fc54931-6560-47f6-ba03-258d40af4091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.07651808],\n",
              "       [-0.06773038],\n",
              "       [ 0.91762122]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# updating the weights (weights optimization)\n",
        "alpha = 0.01\n",
        "weightsOutput = weightsOutput - hiddenLayer.T.dot(deltaOutput)*alpha\n",
        "weightsHidden = weightsHidden - x.T.dot(deltaHidden)*alpha\n",
        "biasOutput = biasOutput - np.sum(deltaOutput)*alpha\n",
        "biasHidden = biasHidden - np.sum(deltaOutput)*alpha"
      ],
      "metadata": {
        "id": "Hp30GhSoPDsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weightsHidden = np.random.uniform(size=(inputNeurons, hiddenNeurons)) # (4,3)\n",
        "biasHidden = np.random.uniform(size=(1, hiddenNeurons)) #(1,3)\n",
        "weightsOutput = np.random.uniform(size=(hiddenNeurons, outputNeurons)) #(3,1)\n",
        "biasOutput = np.random.uniform(size=(1, outputNeurons)) #(1,1)"
      ],
      "metadata": {
        "id": "azel8LO80zp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# need to run the code in a loop and run it until we get an optimized result(combined)\n",
        "\n",
        "alpha = 0.04\n",
        "epochs = 20000\n",
        "\n",
        "for i in range(epochs):\n",
        "  # Step 1 - apply dot product and add bias : f(x) = x.wh + biasHidden\n",
        "  fx = np.dot(x, weightsHidden) + biasHidden\n",
        "\n",
        "  # Step 2 - apply activation function\n",
        "  hiddenLayer = sigmoid(fx)\n",
        "\n",
        "  # Step-3 - apply dot product and add bias : f(x) = hiddenLayer.wout + biasOut\n",
        "  fx_ = np.dot(hiddenLayer, weightsOutput) + biasOutput\n",
        "\n",
        "  # Step 4 - appy activation on output layer\n",
        "  outputLayer = sigmoid(fx_)\n",
        "\n",
        "  errorOutput = outputLayer - y\n",
        "  # Slope on output layer - derivative of activation function applied on this layer\n",
        "  slopeOutput = derivativeSigmoid(outputLayer)\n",
        "  # Delta = error x slope\n",
        "  deltaOutput = errorOutput * slopeOutput\n",
        "\n",
        "  # for hidden layer\n",
        "  errorHidden = np.dot(deltaOutput, weightsOutput.T)\n",
        "  slopeHidden = derivativeSigmoid(hiddenLayer)\n",
        "  deltaHidden = errorHidden * slopeHidden\n",
        "\n",
        "\n",
        "  weightsOutput = weightsOutput - hiddenLayer.T.dot(deltaOutput)*alpha\n",
        "  weightsHidden = weightsHidden - x.T.dot(deltaHidden)*alpha\n",
        "  biasOutput = biasOutput - np.sum(deltaOutput)*alpha\n",
        "  biasHidden = biasHidden - np.sum(deltaOutput)*alpha"
      ],
      "metadata": {
        "id": "kZcM8hhsUiAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputLayer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRZ0JKs5zLMU",
        "outputId": "8e948528-8bc7-49d4-df5e-cb9f241b1f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.98788798],\n",
              "       [0.98006967],\n",
              "       [0.02688157]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ze-3wNM30667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "8e45456b-1092-406c-9ea3-c580c277bbee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6fcf9dfbd479>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "07zWRwb0Jlyw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}