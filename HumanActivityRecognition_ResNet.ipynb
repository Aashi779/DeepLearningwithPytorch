{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aashi779/DeepLearningwithPytorch/blob/main/HumanActivityRecognition_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7pfjdCwAgXy",
        "outputId": "876bcead-3517-43e1-9504-09d5d7991b32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading human-action-recognition-har-dataset.zip to /content\n",
            "100% 296M/297M [00:18<00:00, 19.0MB/s]\n",
            "100% 297M/297M [00:18<00:00, 17.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"ravikanttyagi\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"095a21c789eb4728fde2b29230033273\"\n",
        "\n",
        "!kaggle datasets download meetnagadia/human-action-recognition-har-dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!unzip human-action-recognition-har-dataset.zip\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "7eMBWKppAmsb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms, models\n",
        "from torch.utils import data\n",
        "import torchvision.datasets as datasets"
      ],
      "metadata": {
        "id": "AmjeufQ-ApXa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "-y1qqVQBAwIY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"Human Action Recognition/train\"\n",
        "test_path = \"Human Action Recognition/test\""
      ],
      "metadata": {
        "id": "kwwTx_DxAyPs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Human Action Recognition/Training_set.csv\")\n",
        "class_names = pd.value_counts(df['label']).index\n",
        "class_names = np.sort(class_names)\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaybHdxTAzf2",
        "outputId": "09e8a9ee-02fa-491c-e111-5f50292e6057"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['calling' 'clapping' 'cycling' 'dancing' 'drinking' 'eating' 'fighting'\n",
            " 'hugging' 'laughing' 'listening_to_music' 'running' 'sitting' 'sleeping'\n",
            " 'texting' 'using_laptop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = df['filename'].values"
      ],
      "metadata": {
        "id": "PIl1NSrrEmdo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(filenames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2tv9WyDEmZT",
        "outputId": "4f0483a3-397e-4d69-b619-d0e1cd299add"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12600"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "def load_data(path, df):\n",
        "  images_list = []\n",
        "  labels_list = []\n",
        "  for i in tqdm(range(len(filenames) - 8000)):\n",
        "    # concat train_path with image name\n",
        "    img_path = path + \"/\" + filenames[i]\n",
        "    # fetch image label from data frame of current image\n",
        "    img_label = df['label'][i]\n",
        "    # read image using opencv\n",
        "    img = cv2.imread(img_path)\n",
        "    # resize image because images might be of different dimensions\n",
        "    # in order to maintain array, we have to resize all the images in same dimension\n",
        "    # img = cv2.resize(img, (150,150))\n",
        "    # img = transform(img)\n",
        "    # img = img / 255.0\n",
        "    # store images one by one in your list\n",
        "    images_list.append(img)\n",
        "    labels_list.append(img_label)\n",
        "\n",
        "  images_arr = np.asarray(images_list)\n",
        "  labels_arr = np.asarray(labels_list)\n",
        "\n",
        "  return images_arr, labels_arr"
      ],
      "metadata": {
        "id": "3EMIP6YaA4h-"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, train_labels = load_data(train_path, df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBhgWQHBA7Y4",
        "outputId": "2645dcd2-efdf-4a73-d734-8d22841858bc"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4600/4600 [00:04<00:00, 979.13it/s] \n",
            "<ipython-input-53-ac9a6639ff33>:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  images_arr = np.asarray(images_list)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(train_labels, return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXHRYQxPE8k2",
        "outputId": "34b31128-f228-48b0-f220-2ff9657de428"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['calling', 'clapping', 'cycling', 'dancing', 'drinking', 'eating',\n",
              "        'fighting', 'hugging', 'laughing', 'listening_to_music', 'running',\n",
              "        'sitting', 'sleeping', 'texting', 'using_laptop'], dtype='<U18'),\n",
              " array([322, 312, 315, 296, 307, 313, 307, 316, 332, 272, 290, 317, 315,\n",
              "        283, 303]))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inherit Dataset class coming from data package\n",
        "class Dataset(data.Dataset):\n",
        "  def __init__(self, images, labels):\n",
        "    self.transforms = transforms\n",
        "    self.images = images\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # loading data - one image at a time\n",
        "    X = self.images[index]\n",
        "    X = cv2.resize(X,(224,224))\n",
        "    y = self.labels[index]\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        transforms.RandomHorizontalFlip()\n",
        "        ])\n",
        "    X = transform(X)\n",
        "    # X = torch.tensor(X)\n",
        "    # X = torch.cat((X,X,X),0)\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "hl2FG-K0A94K"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = LabelEncoder()\n",
        "train_labels = label.fit_transform(train_labels)"
      ],
      "metadata": {
        "id": "bFmktAqmBHKu"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 75% - training and 25% - testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.35)"
      ],
      "metadata": {
        "id": "L8i2s08IBM_1"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7bAYXHkFDhp",
        "outputId": "826a093d-80e7-48ba-8c56-591e21d819e9"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2990,)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgqSPVxuFDcD",
        "outputId": "4b1b4f34-b4bd-46ad-88b6-94fc94716f95"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1610,)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\"batch_size\":16, \"shuffle\":True}\n",
        "\n",
        "training_set = Dataset(x_train, y_train)\n",
        "training_generator = data.DataLoader(training_set, **params)\n",
        "\n",
        "test_set = Dataset(x_test, y_test)\n",
        "test_generator = data.DataLoader(test_set, **params)"
      ],
      "metadata": {
        "id": "2C0-dvioBOtv"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "# Evaluation metric\n",
        "def accuracy(y_true, y_pred):\n",
        "  # y_true = 1, y_pred = 1\n",
        "  # y_true = 0, y_pred = 0\n",
        "  correct_classification = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct_classification / len(y_pred)) * 100\n",
        "  return acc\n",
        "\n",
        "def train_step(epoch, model, data, loss_fn, optimizer):\n",
        "  train_loss, train_acc = 0,0\n",
        "  # model.to(device)\n",
        "\n",
        "  for batch, (X, y) in enumerate(data):\n",
        "    X,y = X.to(device), y.to(device)\n",
        "\n",
        "    # Feedforward - it calls forward method inside Model Class\n",
        "    y_pred = model(X)\n",
        "    # Calculate loss\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy(y, y_pred.argmax(dim=1))\n",
        "\n",
        "    # Backpropagate\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss /= len(data)\n",
        "  train_acc /= len(data)\n",
        "  train_acc_history.append(train_acc)\n",
        "  train_loss_history.append(train_loss)\n",
        "  print(f\"Epoch : {epoch} | Train Loss : {train_loss:.3f} |  Train Acc : {train_acc:.3f}\")\n",
        "\n",
        "\n",
        "def test_step(epoch, model, data, loss_fn, optimizer):\n",
        "  test_loss, test_acc = 0,0\n",
        "  # model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X, y) in enumerate(data):\n",
        "      X,y = X.to(device), y.to(device)\n",
        "\n",
        "      # Feedforward - it calls forward method inside Model Class\n",
        "      y_pred = model(X)\n",
        "      # Calculate loss\n",
        "      loss = loss_fn(y_pred, y)\n",
        "      test_loss += loss\n",
        "      test_acc += accuracy(y, y_pred.argmax(dim=1))\n",
        "\n",
        "    test_loss /= len(data)\n",
        "    test_acc /= len(data)\n",
        "    print(f\"Epoch : {epoch} | Test Loss : {test_loss:.3f} |  Test Acc : {test_acc:.3f}\")"
      ],
      "metadata": {
        "id": "DaSQHxxhBQZp"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet = models.resnet18(weights=\"IMAGENET1K_V1\")"
      ],
      "metadata": {
        "id": "0rHaS-NkBfvx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef59841-1a9c-436f-9794-f2815a58a570"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 117MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = model_resnet.fc.in_features"
      ],
      "metadata": {
        "id": "fKFnjBSwCHKq"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2Eu7OjWCOHZ",
        "outputId": "7b98635e-b298-4866-c234-db43731d3a27"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet.fc = nn.Linear(num_features, 15)\n",
        "model_resnet = model_resnet.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_resnet.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "qsZGoMFOCPBm"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc_history = []\n",
        "train_loss_history = []\n",
        "\n",
        "epochs = 15\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  train_step(epoch, model_resnet, training_generator, loss_fn, optimizer)\n",
        "  # test_step(epoch, model_resnet, test_generator, loss_fn, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmouU2dfCty_",
        "outputId": "1db69137-0f1f-4108-e139-da317e315e44"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 1/15 [00:09<02:12,  9.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0 | Train Loss : 2.240 |  Train Acc : 29.665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 2/15 [00:18<02:02,  9.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 | Train Loss : 1.831 |  Train Acc : 40.293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 3/15 [00:29<01:57,  9.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 2 | Train Loss : 1.629 |  Train Acc : 47.130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 4/15 [00:38<01:46,  9.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 3 | Train Loss : 1.473 |  Train Acc : 51.972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 5/15 [00:48<01:36,  9.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 4 | Train Loss : 1.291 |  Train Acc : 58.924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 6/15 [00:57<01:26,  9.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 5 | Train Loss : 1.108 |  Train Acc : 63.780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 7/15 [01:07<01:16,  9.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 6 | Train Loss : 0.962 |  Train Acc : 69.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 8/15 [01:16<01:06,  9.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 7 | Train Loss : 0.789 |  Train Acc : 74.398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 9/15 [01:26<00:57,  9.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 8 | Train Loss : 0.702 |  Train Acc : 77.745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 10/15 [01:35<00:47,  9.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 9 | Train Loss : 0.589 |  Train Acc : 80.720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 11/15 [01:45<00:38,  9.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 10 | Train Loss : 0.496 |  Train Acc : 84.124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 12/15 [01:54<00:28,  9.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 11 | Train Loss : 0.321 |  Train Acc : 89.338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 13/15 [02:04<00:19,  9.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 12 | Train Loss : 0.301 |  Train Acc : 89.902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 14/15 [02:13<00:09,  9.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 13 | Train Loss : 0.333 |  Train Acc : 89.300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [02:23<00:00,  9.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 14 | Train Loss : 0.239 |  Train Acc : 91.663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oMFB7J5WC7hb"
      },
      "execution_count": 67,
      "outputs": []
    }
  ]
}